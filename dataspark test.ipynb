{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imporing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in c:\\users\\kezni\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.9.10)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "# Install the psycopg2 package\n",
    "%pip install psycopg2-binary\n",
    "import psycopg2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the files to separate variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = r'F:\\GUVI\\Projects\\P2 -Data Spark'\n",
    "sales = pd.read_csv(os.path.join(base_path, 'sales.csv'))\n",
    "customers = pd.read_csv(os.path.join(base_path, 'customers.csv'), encoding='ISO 8859-1')\n",
    "products = pd.read_csv(os.path.join(base_path, 'products.csv'))\n",
    "exchange_rates = pd.read_csv(os.path.join(base_path, 'exchange_rates.csv'))\n",
    "stores = pd.read_csv(os.path.join(base_path, 'stores.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying the columns in each dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns for 'sales' after transformation:\n",
      "Index(['order_number', 'line_item', 'order_date', 'delivery_date',\n",
      "       'customerkey', 'storekey', 'productkey', 'quantity', 'currency_code'],\n",
      "      dtype='object') \n",
      "\n",
      "Columns for 'customers' after transformation:\n",
      "Index(['customerkey', 'gender', 'name', 'city', 'state_code', 'state',\n",
      "       'zip_code', 'country', 'continent', 'birthday'],\n",
      "      dtype='object') \n",
      "\n",
      "Columns for 'products' after transformation:\n",
      "Index(['productkey', 'product_name', 'brand', 'color', 'unit_cost_usd',\n",
      "       'unit_price_usd', 'subcategorykey', 'subcategory', 'categorykey',\n",
      "       'category'],\n",
      "      dtype='object') \n",
      "\n",
      "Columns for 'exchange_rates' after transformation:\n",
      "Index(['date', 'currency', 'exchange'], dtype='object') \n",
      "\n",
      "Columns for 'stores' after transformation:\n",
      "Index(['storekey', 'country', 'state', 'square_meters', 'open_date'], dtype='object') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply the operation on column names for each DataFrame in the dictionary\n",
    "dataframes = {\n",
    "    'sales': sales,\n",
    "    'customers': customers,\n",
    "    'products': products,\n",
    "    'exchange_rates': exchange_rates,\n",
    "    'stores': stores\n",
    "}\n",
    "for name, df in dataframes.items():\n",
    "    if isinstance(df, pd.DataFrame):  # Ensure it's a DataFrame\n",
    "        # Perform column name transformation: lowercase and replace spaces with underscores\n",
    "        df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "        print(f\"Columns for '{name}' after transformation:\")\n",
    "        print(df.columns, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for null values & data type in each df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SALES ---\n",
      "Null values per column:\n",
      "order_number     0\n",
      "line_item        0\n",
      "order_date       0\n",
      "delivery_date    0\n",
      "customerkey      0\n",
      "storekey         0\n",
      "productkey       0\n",
      "quantity         0\n",
      "currency_code    0\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "order_number      int64\n",
      "line_item         int64\n",
      "order_date       object\n",
      "delivery_date    object\n",
      "customerkey       int64\n",
      "storekey          int64\n",
      "productkey        int64\n",
      "quantity          int64\n",
      "currency_code    object\n",
      "dtype: object\n",
      "\n",
      "\n",
      "--- CUSTOMERS ---\n",
      "Null values per column:\n",
      "customerkey     0\n",
      "gender          0\n",
      "name            0\n",
      "city            0\n",
      "state_code     10\n",
      "state           0\n",
      "zip_code        0\n",
      "country         0\n",
      "continent       0\n",
      "birthday        0\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "customerkey     int64\n",
      "gender         object\n",
      "name           object\n",
      "city           object\n",
      "state_code     object\n",
      "state          object\n",
      "zip_code       object\n",
      "country        object\n",
      "continent      object\n",
      "birthday       object\n",
      "dtype: object\n",
      "\n",
      "\n",
      "--- PRODUCTS ---\n",
      "Null values per column:\n",
      "productkey        0\n",
      "product_name      0\n",
      "brand             0\n",
      "color             0\n",
      "unit_cost_usd     0\n",
      "unit_price_usd    0\n",
      "subcategorykey    0\n",
      "subcategory       0\n",
      "categorykey       0\n",
      "category          0\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "productkey          int64\n",
      "product_name       object\n",
      "brand              object\n",
      "color              object\n",
      "unit_cost_usd     float64\n",
      "unit_price_usd    float64\n",
      "subcategorykey      int64\n",
      "subcategory        object\n",
      "categorykey         int64\n",
      "category           object\n",
      "dtype: object\n",
      "\n",
      "\n",
      "--- EXCHANGE_RATES ---\n",
      "Null values per column:\n",
      "date        0\n",
      "currency    0\n",
      "exchange    0\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "date         object\n",
      "currency     object\n",
      "exchange    float64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "--- STORES ---\n",
      "Null values per column:\n",
      "storekey         0\n",
      "country          0\n",
      "state            0\n",
      "square_meters    0\n",
      "open_date        0\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "storekey           int64\n",
      "country           object\n",
      "state             object\n",
      "square_meters    float64\n",
      "open_date         object\n",
      "dtype: object\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of dataframes to check for null values and data types\n",
    "dataframes = {\n",
    "    'sales': sales,\n",
    "    'customers': customers,\n",
    "    'products': products,\n",
    "    'exchange_rates': exchange_rates,\n",
    "    'stores': stores\n",
    "}\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    print(f\"--- {name.upper()} ---\")\n",
    "    print(f\"Null values per column:\\n{df.isnull().sum()}\")\n",
    "    print(\"\\nData types:\")\n",
    "    print(df.dtypes)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking how many rows and columns present in each df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SALES ---\n",
      "Number of rows: 62884\n",
      "Number of columns: 9\n",
      "Column names: order_number, line_item, order_date, delivery_date, customerkey, storekey, productkey, quantity, currency_code\n",
      "\n",
      "--- CUSTOMERS ---\n",
      "Number of rows: 15266\n",
      "Number of columns: 10\n",
      "Column names: customerkey, gender, name, city, state_code, state, zip_code, country, continent, birthday\n",
      "\n",
      "--- PRODUCTS ---\n",
      "Number of rows: 2517\n",
      "Number of columns: 10\n",
      "Column names: productkey, product_name, brand, color, unit_cost_usd, unit_price_usd, subcategorykey, subcategory, categorykey, category\n",
      "\n",
      "--- EXCHANGE_RATES ---\n",
      "Number of rows: 11215\n",
      "Number of columns: 3\n",
      "Column names: date, currency, exchange\n",
      "\n",
      "--- STORES ---\n",
      "Number of rows: 67\n",
      "Number of columns: 5\n",
      "Column names: storekey, country, state, square_meters, open_date\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through each dataframe to find the number of columns, rows, and column names\n",
    "for name, df in dataframes.items():\n",
    "    rows, columns = df.shape  \n",
    "    column_names = df.columns.tolist()  \n",
    "    print(f\"--- {name.upper()} ---\")\n",
    "    print(f\"Number of rows: {rows}\")\n",
    "    print(f\"Number of columns: {columns}\")\n",
    "    print(f\"Column names: {', '.join(column_names)}\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing date time and data type formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['order_date'] = pd.to_datetime(sales['order_date'], format='%m/%d/%Y')\n",
    "sales['order_date'] = sales['order_date'].dt.date\n",
    "sales['delivery_date'] = pd.to_datetime(sales['delivery_date'], format='%m/%d/%Y', errors='coerce')\n",
    "sales['delivery_date'] = sales['delivery_date'].dt.date\n",
    "sales.loc[:, 'currency_code'] = sales['currency_code'].astype(str)\n",
    "sales['delivery_date'] = sales['delivery_date'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores['country'] = stores['country'].astype(str)\n",
    "stores['state'] = stores['state'].astype(str)\n",
    "stores['open_date'] = pd.to_datetime(stores['open_date'], format='%m/%d/%Y', errors='coerce')\n",
    "stores['open_date'] = stores['open_date'].dt.date\n",
    "stores['square_meters'] = stores['square_meters'].fillna(stores['square_meters'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers['birthday'] = pd.to_datetime(customers['birthday'], format='%m/%d/%Y', errors='coerce')\n",
    "customers['birthday'] = customers['birthday'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange_rates['date'] = pd.to_datetime(exchange_rates['date'], format='%m/%d/%Y', errors='coerce')\n",
    "exchange_rates['date'] = exchange_rates['date'].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removing $ from respective columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove dollar signs and commas, then convert to float\n",
    "products['unit_cost_usd'] = products['unit_cost_usd'].replace(r'[\\$,]', '', regex=True).astype(float)\n",
    "products['unit_price_usd'] = products['unit_price_usd'].replace(r'[\\$,]', '', regex=True).astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping duplicates present in each column if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.drop_duplicates(inplace=True)\n",
    "exchange_rates.drop_duplicates(inplace=True)\n",
    "customers.drop_duplicates(inplace=True)\n",
    "products.drop_duplicates(inplace=True)\n",
    "stores.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create connection in mysql and creating database - Dataspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database DataSpark created successfully\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "\n",
    "connection = pymysql.connect(host='localhost', user='root', password='root', port=3306)\n",
    "\n",
    "try:\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    database_name = \"DataSpark\"\n",
    "    cursor.execute(f\"CREATE DATABASE {database_name}\")\n",
    "    print(f\"Database {database_name} created successfully\")\n",
    "\n",
    "except pymysql.MySQLError as error:\n",
    "    print(f\"Error occurred: {error}\")\n",
    "\n",
    "finally:\n",
    "    cursor.close()\n",
    "    connection.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the cleaned dfs into mysql database - dataspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully imported customers to sql\n",
      "successfully imported products to sql\n",
      "successfully imported exchange_rates to sql\n",
      "successfully imported stores to sql\n",
      "successfully imported sales to sql\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "host='localhost'\n",
    "user='root'\n",
    "password='root'\n",
    "port=3306\n",
    "database_name = \"DataSpark\"\n",
    "\n",
    "engine_string = f\"mysql+pymysql://{user}:{password}@{host}:{port}/{database_name}\"\n",
    "engine = create_engine(engine_string)\n",
    "\n",
    "\n",
    "table_name =\"customers\"\n",
    "customers.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "print(f\"successfully imported {table_name} to sql\")\n",
    "\n",
    "table_name = \"products\"\n",
    "products.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "print(f\"successfully imported {table_name} to sql\")\n",
    "\n",
    "table_name = \"exchange_rates\"\n",
    "exchange_rates.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "print(f\"successfully imported {table_name} to sql\")\n",
    "\n",
    "table_name = \"stores\"\n",
    "stores.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "print(f\"successfully imported {table_name} to sql\")\n",
    "\n",
    "table_name = \"sales\"\n",
    "sales.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "print(f\"successfully imported {table_name} to sql\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
